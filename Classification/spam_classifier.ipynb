{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88cf31b",
   "metadata": {},
   "source": [
    "# Spam Classifier\n",
    "\n",
    "The puporse of this project is to detect an Email as Spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d6a9ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's fetch the data:\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20050311_spam_2.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in (('easy_ham.tar.bz2',ham_url),('spam_2.tar.bz2',spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b9b3780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e639f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's load all the emails:\n",
    "\n",
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam_2\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a3120d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9ae66651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8d9874a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use Python's email module to parse these emails (this handles headers, encoding, and so on):\n",
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam_2\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "40e10d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2054e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path: <Steve_Burt@cursor-system.com>\n",
      "Delivered-To: zzzz@localhost.netnoteinc.com\n",
      "Received: from localhost (localhost [127.0.0.1])\n",
      "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id BE12E43C34\n",
      "\tfor <zzzz@localhost>; Thu, 22 Aug 2002 07:46:38 -0400 (EDT)\n",
      "Received: from phobos [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 12:46:38 +0100 (IST)\n",
      "Received: from n20.grp.scd.yahoo.com (n20.grp.scd.yahoo.com    [66.218.66.76])\n",
      " by dogma.slashnull.org (8.11.6/8.11.6) with SMTP id    g7MBkTZ05087 for\n",
      " <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 12:46:29 +0100\n",
      "X-Egroups-Return: =?utf-8?q?sentto-2242572-52726-1030016790-zzzz=3Dspamassas?=\n",
      " =?utf-8?q?sin=2Etaint=2Eorg=40returns=2Egroups=2Eyahoo=2Ecom?=\n",
      "Received: from [66.218.67.196] by n20.grp.scd.yahoo.com with NNFMP;\n",
      "    22 Aug 2002 11:46:30 -0000\n",
      "X-Sender: steve.burt@cursor-system.com\n",
      "X-Apparently-To: zzzzteana@yahoogroups.com\n",
      "Received: (EGP: mail-8_1_0_1); 22 Aug 2002 11:46:29 -0000\n",
      "Received: (qmail 11764 invoked from network); 22 Aug 2002 11:46:29 -0000\n",
      "Received: from unknown (66.218.66.217) by m3.grp.scd.yahoo.com with QMQP;\n",
      "    22 Aug 2002 11:46:29 -0000\n",
      "Received: from unknown (HELO mailgateway.cursor-system.com) (62.189.7.27)\n",
      "    by mta2.grp.scd.yahoo.com with SMTP; 22 Aug 2002 11:46:29 -0000\n",
      "Received: from exchange1.cps.local (unverified) by\n",
      "    mailgateway.cursor-system.com (Content Technologies SMTPRS 4.2.10) with\n",
      "    ESMTP id <T5cde81f695ac1d100407d@mailgateway.cursor-system.com> for\n",
      "    <forteana@yahoogroups.com>; Thu, 22 Aug 2002 13:14:10 +0100\n",
      "Received: by exchange1.cps.local with Internet Mail Service (5.5.2653.19)\n",
      "    id <PXX6AT23>; Thu, 22 Aug 2002 12:46:27 +0100\n",
      "Message-Id: <5EC2AD6D2314D14FB64BDA287D25D9EF12B4F6@exchange1.cps.local>\n",
      "To: \"'zzzzteana@yahoogroups.com'\" <zzzzteana@yahoogroups.com>\n",
      "X-Mailer: Internet Mail Service (5.5.2653.19)\n",
      "X-Egroups-From: Steve Burt <steve.burt@cursor-system.com>\n",
      "From: Steve Burt <Steve_Burt@cursor-system.com>\n",
      "X-Yahoo-Profile: pyruse\n",
      "MIME-Version: 1.0\n",
      "Mailing-List: list zzzzteana@yahoogroups.com; contact\n",
      "    forteana-owner@yahoogroups.com\n",
      "Delivered-To: mailing list zzzzteana@yahoogroups.com\n",
      "Precedence: bulk\n",
      "List-Unsubscribe: <mailto:zzzzteana-unsubscribe@yahoogroups.com>\n",
      "Date: Thu, 22 Aug 2002 12:46:18 +0100\n",
      "Subject: [zzzzteana] RE: Alexander\n",
      "Reply-To: zzzzteana@yahoogroups.com\n",
      "Content-Type: text/plain; charset=US-ASCII\n",
      "Content-Transfer-Encoding: 7bit\n",
      "\n",
      "Martin A posted:\n",
      "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
      " limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\n",
      " Mount Athos monastic community, was ideal for the patriotic sculpture. \n",
      " \n",
      " As well as Alexander's granite features, 240 ft high and 170 ft wide, a\n",
      " museum, a restored amphitheatre and car park for admiring crowds are\n",
      "planned\n",
      "---------------------\n",
      "So is this mountain limestone or granite?\n",
      "If it's limestone, it'll weather pretty fast.\n",
      "\n",
      "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
      "4 DVDs Free +s&p Join Now\n",
      "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
      "---------------------------------------------------------------------~->\n",
      "\n",
      "To unsubscribe from this group, send an email to:\n",
      "forteana-unsubscribe@egroups.com\n",
      "\n",
      " \n",
      "\n",
      "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's look at one example of ham email, to get a feel of what the data looks like:\n",
    "\n",
    "print(ham_emails[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "82bfd1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path: merchantsworld2001@juno.com\n",
      "Delivery-Date: Thu May 16 11:03:55 2002\n",
      "Received: from mandark.labs.netnoteinc.com ([213.105.180.140]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g4GA3qe29480 for\n",
      "    <jm@jmason.org>; Thu, 16 May 2002 11:03:52 +0100\n",
      "Received: from webnote.net (mail.webnote.net [193.120.211.219]) by\n",
      "    mandark.labs.netnoteinc.com (8.11.2/8.11.2) with ESMTP id g4GA3oD28650 for\n",
      "    <jm@netnoteinc.com>; Thu, 16 May 2002 11:03:51 +0100\n",
      "Received: from webcust2.hightowertech.com (webcust2.hightowertech.com\n",
      "    [216.41.166.100]) by webnote.net (8.9.3/8.9.3) with ESMTP id BAA11067 for\n",
      "    <jm@netnoteinc.com>; Thu, 16 May 2002 01:58:00 +0100\n",
      "Received: from html ([199.35.236.73]) by webcust2.hightowertech.com  with\n",
      "    Microsoft SMTPSVC(5.5.1877.197.19); Wed, 15 May 2002 13:50:57 -0700\n",
      "From: jordan23@mailexcite.com\n",
      "To: ranmoore@swbell.net\n",
      "Subject: New Improved Fat Burners, Now With TV Fat Absorbers! Time:7:20:54 AM\n",
      "Date: Thu, 31 Jul 1980 07:20:54\n",
      "MIME-Version: 1.0\n",
      "Message-Id: <0925c5750200f52WEBCUST2@webcust2.hightowertech.com>\n",
      "X-Keywords: \n",
      "Content-Type: text/html; charset=\"DEFAULT\"\n",
      "\n",
      "<html>\n",
      "<body>\n",
      "<center>\n",
      "<b>\n",
      "<font color=\"blue\">\n",
      "*****Bonus Fat Absorbers As Seen On TV, Included Free With Purchase Of 2 Or More Bottle, $24.95 Value*****\n",
      "</font>\n",
      "<br>\n",
      "<br>\n",
      "***TAKE $10.00 OFF 2 & 3 MONTH SUPPLY ORDERS, $5.00 OFF 1 MONTH SUPPLY!\n",
      "***AND STILL GET YOUR BONUS!  PRICE WILL BE DEDUCTED DURING PROCESSING.\n",
      "<br>\n",
      "<br>\n",
      "***FAT ABSORBERS ARE GREAT FOR THOSE WHO WANT TO LOSE WEIGHT,  BUT CAN'T STAY ON A DIET***\n",
      "<br>\n",
      "<br>\n",
      "***OFFER GOOD UNTIL MAY 27, 2002!  FOREIGN ORDERS INCLUDED!\n",
      "<br>\n",
      "<br>\n",
      "\n",
      "<font color=\"blue\">\n",
      "\n",
      "LOSE 30 POUNDS  IN 30 DAYS... GUARANTEED!!!\n",
      "<br>\n",
      "<br>\n",
      "\n",
      "All Natural Weight-Loss Program, Speeds Up The Metabolism Safely\n",
      "Rated #1 In Both Categories of SAFETY & EFFECTIVENESS In<br>\n",
      "(THE United States Today)\n",
      "<br><br>\n",
      "WE'LL HELP YOU GET THINNER!\n",
      "WE'RE GOING TO HELP YOU LOOK GOOD, FEEL GOOD AND TAKE CONTROL IN\n",
      "2002\n",
      "<br>\n",
      "<br>\n",
      "</b>\n",
      "</font color=\"blue\">\n",
      "</center>\n",
      "\n",
      "Why Use Our Amazing Weight Loss Capsules?\n",
      "<br><br>\n",
      "*  They act like a natural magnet to attract fat.<br>\n",
      "*  Stimulates the body's natural metabolism. <br>\n",
      "*  Controls appetite naturally and makes it easier to\n",
      "   eat the right foods consistently.<br>\n",
      "*  Reduces craving for sweets.<br>\n",
      "*  Aids in the absorption of fat and in overall digestion.<br>\n",
      "*  Inhibits bad cholesterol and boosts good cholesterol.<br>\n",
      "*  Aids in the process of weight loss and long-term weight management.<br>\n",
      "*  Completely safe, UltraTrim New Century contains no banned\n",
      "   substances and has no known side effects.<br>\n",
      "<br>\n",
      "What Makes UltraTrim New Century Unique?\n",
      "<br><br>\n",
      "A scientifically designed combination of natural ingredients that\n",
      "provide long-term weight management in a safe and effective manner.\n",
      "<br><br>\n",
      "*****<br>\n",
      "Receive A Bonus Supply Of Ultra Trim New Century & A Bottle Of Fat Absorbers Listed Above, \n",
      "With Every Order Of 2 Or More Bottles. Offer Good Until May. 27, 2002! <br>\n",
      "*****\n",
      "<br><br>\n",
      "WE GLADLY SHIP TO ALL FOREIGN COUNTRIES! \n",
      "<br><br>\n",
      "You will be losing by tomorrow!  Don't Wait, visit our web\n",
      "page below, and order now!\n",
      "<br><br>\n",
      "Email Address:   <a\n",
      "href=\"mailto:ultratrimnow2001@aol.com\">ultratrimnow2001@aol.com</a>\n",
      "<br><br>\n",
      "Order by 24 Hour Fax!!!  775-257-6657.<br>\n",
      "<br>\n",
      "*****************<br>\n",
      "<a\n",
      "href=\"http://www.geocities.com/ultra_weightloss_2002/\">http://www.geocities.com/ultra_weightloss_2002/</a><br>\n",
      "*****************\n",
      "<br><br>\n",
      "This is the easiest, fastest, and most effective way to lose both\n",
      "pounds and inches permanently!!!  This weight loss program is\n",
      "designed specifically to \"boost\" weight-loss efforts by assisting\n",
      "body metabolism, and helping the body's ability to manage weight.\n",
      "A powerful, safe, 30 Day Program.  This is one program you won't\n",
      "feel starved on.  Complete program for one amazing low price!\n",
      "Program includes: <b>BONUS AMAZING FAT ABSORBER CAPSULES, 30 DAY -\n",
      "WEIGHT\n",
      "REDUCTION PLAN, PROGRESS REPORT!</b>\n",
      "<br><br>\n",
      "SPECIAL BONUS...\"FAT ABSORBERS\", AS SEEN ON TV\n",
      "With every order...AMAZING MELT AWAY FAT ABSORBER CAPSULES with\n",
      "directions ( Absolutely Free ) ...With these capsules\n",
      "you can eat what you enjoy, without the worry of fat in your diet.\n",
      "2 to 3 capsules 15 minutes before eating or snack, and the fat will be\n",
      "absorbed and passed through the body without the digestion of fat into\n",
      "the body. \n",
      "<br><br>\n",
      "You will be losing by tomorrow!  Don't Wait, visit our web\n",
      "page below, and order now!\n",
      "<br><br>\n",
      "Email Address:  <a href=\"mailto:ultratrimnow2001@aol.com\">ultratrimnow2001@aol.com</a>\n",
      "<br><br>\n",
      "\n",
      "Order by 24 Hour Fax!!!  775-257-6657.<br>\n",
      "<br>\n",
      "*****************<br>\n",
      "<a\n",
      "href=\"http://www.geocities.com/ultra_weightloss_2002/\">http://www.geocities.com/ultra_weightloss_2002/</a><br>\n",
      "*****************\n",
      "<br><br>\n",
      "___1 Month Supply $32.95 plus $4.75 S & H, 100 Amazing MegaTrim\n",
      "     Capsules.\n",
      "<br><br>\n",
      "___2 Month Supply $54.95 plus $4.75 S & H, 200 Amazing MegaTrim\n",
      "     Capsules.  (A $10.95 Savings, Free Bottle)!\n",
      "<br><br>\n",
      "___3 Month Supply $69.95,  Plus $4.75 S & H, 300 Amazing MegaTrim\n",
      "     Capsules.  (A $28.90 Savings, Free Bottle)!\n",
      "<br><br>\n",
      "To Order by postal mail, please send to the below address.\n",
      "Make payable to UltraTrim 2002.\n",
      "<br><br>\n",
      "Ultra Trim 2002<br>\n",
      "4132 Pompton Ct.<br>\n",
      "Dayton, Ohio  45405<br>\n",
      "(937) 567-9807<br>\n",
      "<br>\n",
      "Order by 24 Hour Voice/Fax!!!  775-257-6657.<br>\n",
      "<br>\n",
      "*****<br>\n",
      "<b><font color=\"red\">Important Credit Card Information! Please Read Below!</b></font>\n",
      " <br><br>\n",
      "*     Credit Card Address, City, State and Zip Code, must match\n",
      "      billing address to be processed. \n",
      "<br><br>\n",
      "\n",
      "___Check<br>\n",
      "___MoneyOrder<br>\n",
      "___Visa<br>\n",
      "___MasterCard<br>\n",
      "___AmericanExpress<br>\n",
      "___Debt Card\n",
      "<br><br>\n",
      "Name_______________________________________________________<br>\n",
      "(As it appears on Check or Credit Card)\n",
      "<br><br>\n",
      "Address____________________________________________________<br>\n",
      "(As it appears on Check or Credit Card)\n",
      "<br><br>\n",
      "___________________________________________________<br>\n",
      "City,State,Zip(As it appears on Check or Credit Card)\n",
      "<br><br>\n",
      "___________________________________________________<br>\n",
      "Country\n",
      "<br><br>\n",
      "___________________________________________________<br>\n",
      "(Credit Card Number)\n",
      "<br><br>\n",
      "Expiration Month_____  Year_____\n",
      "<br><br>\n",
      "___________________________________________________<br>\n",
      "Authorized Signature\n",
      "<br><br>\n",
      "<b>\n",
      "*****IMPORTANT NOTE*****\n",
      "</b>\n",
      "<br><br>\n",
      "If Shipping Address Is Different From The Billing Address Above,\n",
      "Please Fill Out Information Below.\n",
      "<br><br>\n",
      "Shipping Name______________________________________________\n",
      "<br><br>\n",
      "Shipping Address___________________________________________\n",
      "<br><br>\n",
      "___________________________________________________________<br>\n",
      "Shipping City,State,Zip\n",
      "<br><br>\n",
      "___________________________________________________________<br>\n",
      "Country\n",
      "<br><br>\n",
      "___________________________________________________________<br>\n",
      "Email Address & Phone Number(Please Write Neat)\n",
      "<br>\n",
      "<br>\n",
      "<center>\n",
      "<a\n",
      "href=\"mailto:ultratrim2002dontsend@yahoo.com\">To Be Removed From Our Mail List, Click Here And Put The Word Remove In The Subject Line.</a>\n",
      "</center>\n",
      "<br>\n",
      "<br>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's look at one example of spam email, to get a feel of what the data looks like:\n",
    "\n",
    "print(spam_emails[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "60917b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some emails are actually multipart, with images and attachments (which can have their own attachments). \n",
    "# Let's look at the various types of structures of emails we have:\n",
    "\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f5558af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c336ec43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the structure of Ham Emails\n",
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c4f62f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 597),\n",
       " ('text/html', 589),\n",
       " ('multipart(text/plain, text/html)', 114),\n",
       " ('multipart(text/html)', 29),\n",
       " ('multipart(text/plain)', 25),\n",
       " ('multipart(multipart(text/html))', 18),\n",
       " ('multipart(multipart(text/plain, text/html))', 5),\n",
       " ('multipart(text/plain, application/octet-stream, text/plain)', 3),\n",
       " ('multipart(text/html, text/plain)', 2),\n",
       " ('multipart(text/html, image/jpeg)', 2),\n",
       " ('multipart(multipart(text/plain), application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/gif)',\n",
       "  1),\n",
       " ('text/plain charset=us-ascii', 1),\n",
       " ('multipart(multipart(text/html), image/gif)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), application/octet-stream, application/octet-stream, application/octet-stream, application/octet-stream)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif, image/jpeg)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the structure of Spam Emails\n",
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b8857d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <ilug-admin@linux.ie>\n",
      "Delivered-To : yyyy@localhost.netnoteinc.com\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)\n",
      "Received : from phobos [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)\n",
      "Received : from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100\n",
      "Received : from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100\n",
      "Received : from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100\n",
      "X-Authentication-Warning : lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net    [64.0.57.142] claimed to be bettyjagessar.com\n",
      "Received : from 64.0.57.142 [202.63.165.34] by bettyjagessar.com    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400\n",
      "Message-Id : <1028311679.886@0.57.142>\n",
      "Date : Fri, 02 Aug 2002 23:37:59 +0530\n",
      "To : ilug@linux.ie\n",
      "From : Start Now <startnow2002@hotmail.com>\n",
      "MIME-Version : 1.0\n",
      "Content-Type : text/plain; charset=\"US-ASCII\"; format=\"flowed\"\n",
      "Subject : [ILUG] STOP THE MLM INSANITY\n",
      "Sender : ilug-admin@linux.ie\n",
      "Errors-To : ilug-admin@linux.ie\n",
      "X-Mailman-Version : 1.1\n",
      "Precedence : bulk\n",
      "List-Id : Irish Linux Users' Group <ilug.linux.ie>\n",
      "X-Beenthere : ilug@linux.ie\n"
     ]
    }
   ],
   "source": [
    "# Now let's take a look at the email headers:\n",
    "for header, value in spam_emails[0].items():\n",
    "    print(header,\":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "097c74c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ILUG] STOP THE MLM INSANITY'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "622ec9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "\n",
    "# Function to convert html emails content to plain text\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    \"Creates a formatted text email message as a string from a rendered html template (page)\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Ignore anything in head\n",
    "    body, text = soup.body, []\n",
    "    if body:\n",
    "        for element in body.descendants:\n",
    "            # We use type and not isinstance since comments, cdata, etc are subclasses that we don't want\n",
    "            if type(element) == NavigableString:\n",
    "                parent_tags = (t for t in element.parents if type(t) == Tag)\n",
    "                hidden = False\n",
    "                for parent_tag in parent_tags:\n",
    "                    # Ignore any text inside a non-displayed tag\n",
    "                    # We also behave is if scripting is enabled (noscript is ignored)\n",
    "                    # The list of non-displayed tags and attributes from the W3C specs:\n",
    "                    if (parent_tag.name in ('area', 'base', 'basefont', 'datalist', 'head', 'link',\n",
    "                                            'meta', 'noembed', 'noframes', 'param', 'rp', 'script',\n",
    "                                            'source', 'style', 'template', 'track', 'title', 'noscript') or\n",
    "                        parent_tag.has_attr('hidden') or\n",
    "                        (parent_tag.name == 'input' and parent_tag.get('type') == 'hidden')):\n",
    "                        hidden = True\n",
    "                        break\n",
    "                if hidden:\n",
    "                    continue\n",
    "\n",
    "                # remove any multiple and leading/trailing whitespace\n",
    "                string = ' '.join(element.string.split())\n",
    "                if string:\n",
    "                    if element.parent.name == 'a':\n",
    "                        a_tag = element.parent\n",
    "                        # replace link text with the link\n",
    "                        string = a_tag.get('href')\n",
    "                        # concatenate with any non-empty immediately previous string\n",
    "                        if (type(a_tag.previous_sibling) == NavigableString and\n",
    "                                a_tag.previous_sibling.string.strip() and string):\n",
    "                            text[-1] = text[-1] + ' ' + string\n",
    "                            continue\n",
    "                    elif element.previous_sibling and element.previous_sibling.name == 'a' and string:\n",
    "                        if text:\n",
    "                            text[-1] = text[-1] + ' ' + string\n",
    "                        continue\n",
    "                    elif element.parent.name == 'p' and string:\n",
    "                        # Add extra paragraph formatting newline\n",
    "                        string = '\\n' + string\n",
    "                    if string:\n",
    "                        text += [string]\n",
    "                    else:\n",
    "                        text +=[\"\"]\n",
    "                        \n",
    "        doc = '\\n'.join(text)\n",
    "        return doc\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1eaa9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<html><body>\n",
      "\n",
      "<center>\n",
      "<font face=\"arial\"><b>Talk on Tele  with locals in your area who want to meet for real encounters. \n",
      " No pre recorded bull this is the real deal.\n",
      "<p>\n",
      "\n",
      "US residents: the 9<!--dads tools-->00-370-54<!--starter-->65 or  8<!--ender-->88-400-1<!--end-->919. - 99<!--hi hi -->\n",
      " cents / min\n",
      "<p>\n",
      "\n",
      "For CA callers try our special California  line, California is so popular we had to create a seperate system just for them\n",
      "<p>\n",
      ": 1-<!--moms-->9<!--low-->00-505-7575.\n",
      "<p>\n",
      "must be 18<!--none-->+ be careful when making sexual dates and meetings. Cali 9<!--polic cars-->00# is $1.99 per min\n",
      "\n",
      "</html>\n",
      "\n",
      "211075433222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's see how it works for some HTML spam emails:\n",
    "\n",
    "html_spam_emails = [email for email in spam_emails\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aa464174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk on Tele with locals in your area who want to meet for real encounters. No pre recorded bull this is the real deal.\n",
      "\n",
      "US residents: the 9\n",
      "\n",
      "00-370-54\n",
      "\n",
      "65 or 8\n",
      "\n",
      "88-400-1\n",
      "\n",
      "919. - 99\n",
      "\n",
      "cents / min\n",
      "\n",
      "For CA callers try our special California line, California is so popular we had to create a seperate system just for them\n",
      "\n",
      ": 1-\n",
      "\n",
      "9\n",
      "\n",
      "00-505-7575.\n",
      "\n",
      "must be 18\n",
      "\n",
      "+ be careful when making sexual dates and meetings. Cali 9\n",
      "\n",
      "00# is $1.99 per min\n"
     ]
    }
   ],
   "source": [
    "# And this is the resulting plain text:\n",
    "\n",
    "print(html_to_plain_text(sample_html_spam.get_content()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ebbaf62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the contents of an email. Here we are considering only text or html content.\n",
    "\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "52c23c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk on Tele with locals in your area who want to meet for real encounters. No pre recorded bull this is the real deal.\n",
      "\n",
      "US residents: the 9\n",
      "\n",
      "00-370-54\n",
      "\n",
      "65 or 8\n",
      "\n",
      "88-400-1\n",
      "\n",
      "919. - 99\n",
      "\n",
      "cents / min\n",
      "\n",
      "For CA callers try our special California line, California is so popular we had to create a seperate system just for them\n",
      "\n",
      ": 1-\n",
      "\n",
      "9\n",
      "\n",
      "00-505-7575.\n",
      "\n",
      "must be 18\n",
      "\n",
      "+ be careful when making sexual dates and meetings. Cali 9\n",
      "\n",
      "00# is $1.99 per min\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43fb1c8",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Now its time to split our data into a training set and a testing set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "88f88ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84aab9d",
   "metadata": {},
   "source": [
    "<b> We will create a transformer that will convert emails to word counters. Note that we will split sentences into words using Python's split() method, which uses whitespaces for word boundaries.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e8cf9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "        self.url_extractor = urlextract.URLExtract()\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls is not None:\n",
    "                urls = list(set(self.url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and self.stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = self.stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "80d478b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'number': 8, 'to': 4, 'a': 4, 'the': 4, 'url': 2, 'ubi': 2, 'china': 2, 'for': 2, 'local': 2, 'date': 1, 'numbertnumb': 1, 'had': 1, 'alway': 1, 'want': 1, 'make': 1, 'pc': 1, 'game': 1, 'market': 1, 'but': 1, 'factor': 1, 'kept': 1, 'idea': 1, 'on': 1, 'hold': 1, 'in': 1, 'januari': 1, 'right': 1, 'incent': 1, 'motiv': 1, 'tri': 1, 'project': 1, 'final': 1, 'arriv': 1, 'licens': 1, 'music': 1, 'up': 1, 'popular': 1, 'anim': 1, 'properti': 1}),\n",
       "       Counter({'number': 6, 'to': 5, 'you': 5, 'the': 4, 'of': 4, 'receiv': 4, 'thi': 3, 'not': 3, 'email': 3, 'our': 3, 'offer': 3, 'plan': 2, 'at': 2, 'and': 2, 'enrol': 2, 'is': 2, 'in': 2, 'are': 2, 'by': 2, 'sign': 1, 'up': 1, 'for': 1, 'full': 1, 'access': 1, 'medic': 1, 'llc': 1, 'applic': 1, 'must': 1, 'be': 1, 'least': 1, 'pay': 1, 'a': 1, 'one': 1, 'time': 1, 'fee': 1, 'regardless': 1, 'depend': 1, 'non': 1, 'insur': 1, 'healthcar': 1, 'avail': 1, 'washington': 1, 'sent': 1, 'unsolicit': 1, 'it': 1, 'becaus': 1, 'request': 1, 'opt': 1, 'with': 1, 'market': 1, 'partner': 1, 'will': 1, 'notic': 1, 'excit': 1, 'product': 1, 'other': 1, 'option': 1, 'howev': 1, 'we': 1, 'commit': 1, 'onli': 1, 'send': 1, 'those': 1, 'peopl': 1, 'that': 1, 'desir': 1, 'these': 1, 'if': 1, 'do': 1, 'wish': 1, 'such': 1, 'click': 1, 'here': 1, 'or': 1, 'past': 1, 'follow': 1, 'into': 1, 'ani': 1, 'browser': 1, 'url': 1, 'remov': 1, 'your': 1, 'name': 1, 'from': 1, 'list': 1, 'may': 1, 'contact': 1, 'compani': 1, 'mail': 1, 's': 1, 'e': 1, 'numberth': 1, 'street': 1, 'suit': 1, 'ft': 1, 'lauderdal': 1, 'fl': 1}),\n",
       "       Counter({'number': 20, 'of': 10, 'the': 9, 'to': 9, 'that': 7, 'rdf': 6, 'for': 6, 'it': 6, 'a': 6, 'url': 5, 'with': 5, 'i': 5, 'in': 4, 'by': 4, 'write': 4, 'thi': 3, 'project': 3, 'is': 3, 'good': 3, 's': 3, 'an': 3, 'be': 3, 'schema': 3, 'but': 3, 'xml': 3, 'and': 3, 'hand': 3, 'on': 2, 'so': 2, 'answer': 2, 'whole': 2, 'what': 2, 'thing': 2, 'someon': 2, 'infinit': 2, 'can': 2, 'awar': 2, 'or': 2, 'at': 2, 'tramp': 2, 'make': 2, 'python': 2, 'data': 2, 'you': 2, 'have': 2, 'may': 2, 'use': 2, 'are': 2, 'will': 2, 'add': 2, 'anoth': 2, 'layer': 2, 'tedium': 2, 'html': 2, 'date': 1, 'numbertnumb': 1, '_phil': 1, 'ringnalda_': 1, 'put': 1, 'brake': 1, 'question': 1, 'start': 1, 'rss': 1, 'two': 1, 'who': 1, 'ha': 1, 'larg': 1, 'databas': 1, 'queri': 1, 'fast': 1, 'program': 1, 'aggreg': 1, 'tri': 1, 'figur': 1, 'out': 1, 'should': 1, 'do': 1, 'new': 1, 'element': 1, 'hasn': 1, 't': 1, 'seen': 1, 'befor': 1, 'actual': 1, 'interest': 1, 'some': 1, 'potenti': 1, 'success': 1, 'point': 1, 'm': 1, 'sick': 1, 'll': 1, 'leav': 1, 'els': 1, '_aaron': 1, 'swartz_': 1, 'look': 1, 'like': 1, 'structur': 1, 'got': 1, 'down': 1, 'tire': 1, 'go': 1, 'through': 1, 'contort': 1, 'deal': 1, 'want': 1, 'standard': 1, 'compat': 1, 'same': 1, 'time': 1, 'need': 1, 'modul': 1, 'implement': 1, 'psuedo': 1, 'code': 1, 'had': 1, 'your': 1, 'slide': 1, 'not': 1, 'these': 1, 'problem': 1, 'complet': 1, 'exampl': 1, 'pars': 1, 'foaf': 1, 'file': 1, '_dan': 1, 'connolly_': 1, 'hyperrdf': 1, 'xhtml': 1, 'author': 1, 'tool': 1, 'xslt': 1, 'produc': 1, 'syntax': 1, 'littl': 1, 'tediou': 1, 'lot': 1, 'peopl': 1, 'evid': 1, 'abl': 1, 'edit': 1, 'there': 1, 'still': 1, 'few': 1, 'folk': 1, 'heavi': 1, 'reific': 1, 'quot': 1, 'my': 1, 'represent': 1, 'logic': 1, 'formula': 1, 'find': 1, 'unmanag': 1, 'been': 1, 'sgml': 1, 'year': 1, 'also': 1, 'includ': 1, 'cogent': 1, 'explan': 1, 'obscur': 1, 'profil': 1, 'attribut': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ffc42",
   "metadata": {},
   "source": [
    "Now we have the word counts, and we need to convert them to vectors. For this, we will build another transformer whose fit() method will build the vocabulary (an ordered list of the most common words) and whose transform() method will use the vocabulary to convert word counts to vectors. The output is a sparse matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e6f5df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a7ad9998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 30 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f51c2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35,   8,   4,   4,   0,   4,   2,   2,   0,   1,   0],\n",
       "       [107,   6,   5,   4,   4,   1,   1,   1,   1,   2,   5],\n",
       "       [230,  20,   9,   9,  10,   6,   6,   5,   7,   4,   2]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011ad61",
   "metadata": {},
   "source": [
    "What does this matrix mean? Well, the 107 in the second row, first column, means that the second email contains 107 words that are not part of the vocabulary. The 6 next to it means that the first word in the vocabulary is present 6 times in this email. The 5 next to it means that the second word is present 5 times, and so on. We can look at the vocabulary to know which words we are talking about. The first word is \"number\", the second word is \"a\", etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f21a3c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': 1,\n",
       " 'to': 2,\n",
       " 'the': 3,\n",
       " 'of': 4,\n",
       " 'a': 5,\n",
       " 'for': 6,\n",
       " 'url': 7,\n",
       " 'that': 8,\n",
       " 'in': 9,\n",
       " 'you': 10}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4788d",
   "metadata": {},
   "source": [
    "We are now ready to train our first spam classifier! Let's transform the whole dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1dfe2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a31b6b",
   "metadata": {},
   "source": [
    "### Training the LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "56efe11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "log_clf.fit(X_train_transformed,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609edd14",
   "metadata": {},
   "source": [
    "### Predictions and Evaluation of LogisticRegression\n",
    "Create predictions from the test set and create a classification report and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "83060f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "predictions = log_clf.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0b5d11f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       496\n",
      "           1       0.96      0.99      0.97       284\n",
      "\n",
      "    accuracy                           0.98       780\n",
      "   macro avg       0.98      0.98      0.98       780\n",
      "weighted avg       0.98      0.98      0.98       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d7337dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[484  12]\n",
      " [  3 281]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a56002c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 95.90%\n",
      "Recall: 98.94%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, predictions)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d166260",
   "metadata": {},
   "source": [
    "### Training the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3ee81e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=300)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=300)\n",
    "\n",
    "rfc.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b21ff2",
   "metadata": {},
   "source": [
    "### Predictions and Evaluation\n",
    "Let's predict off the y_test values and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "dd6a01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictions = rfc.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c1c86f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       496\n",
      "           1       0.99      0.96      0.98       284\n",
      "\n",
      "    accuracy                           0.98       780\n",
      "   macro avg       0.99      0.98      0.98       780\n",
      "weighted avg       0.98      0.98      0.98       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,rfc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f3646df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[494   2]\n",
      " [ 10 274]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rfc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "185f1a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 99.28%\n",
      "Recall: 96.48%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, rfc_predictions)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, rfc_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5e24bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read an email.\n",
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def read_eml_files(path='./datasets/spam/'):\n",
    "    eml_files = glob.glob(path + '*.eml') # get all .eml files in a list\n",
    "    email_contents =[]\n",
    "    for eml_file in eml_files:\n",
    "        print(eml_file)\n",
    "        with open(os.path.join(eml_file), \"rb\") as f:\n",
    "            email_contents.append(email.parser.BytesParser(policy=email.policy.default).parse(f))\n",
    "    return email_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "209c0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/spam/report.eml\n",
      "./datasets/spam/Assured great returns and cashback await you🤑.eml\n"
     ]
    }
   ],
   "source": [
    "# Let's test with some email from the Gmail\n",
    "test_emails = read_eml_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b30194a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emails_transformed = preprocess_pipeline.transform(test_emails)\n",
    "predictions_emails = rfc.predict(test_emails_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "76c96945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's check the predictions, 0 for ham and 1 for spam.\n",
    "print(predictions_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720fae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
